{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control Variates for a GARCH Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "### I - Presentation of the ZV principle of the article, in a general case\n",
    "### II - Implementation of a Random Walk Metropolis Sampler\n",
    "### III - Use of Control Variates\n",
    "### IV - Expansion to Higher Order Polynomials\n",
    "### V - Bonus: Linear Regression Validity\n",
    "### VI - Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I - Presentation of the ZV principle of the article, in a general case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les méthodes MCMC déjà existantes sont déjà utilisées pour estimer l'espérance d'une fonction $f(x)$ par rapport à une probabilité de densité $\\pi(x)$, non nécessairement normalisée. Cette espérance s'exprime par la quantité suivante: $$ \\mu_f = \\frac{\\int f(x)\\pi(x)dx}{\\int \\pi(x)dx} $$\n",
    "\n",
    "En pratique, les MCMC estiment $\\mu_f$ en prenant la moyenne des $f(x_i)$ avec les $x_i$ des échantillons issus d'une chaîne de Markov qui a $\\pi$ comme mesure stationnaire. Ceci donne alors l'estimateur suivant:\n",
    "$$ \\hat{\\mu}_f = \\frac{1}{N}\\sum_{i=1}^{N}f(x_i) $$\n",
    "\n",
    "L'idée innovante du premier article proposé est de réduire la variance de l'estimateur MCMC, $\\hat{\\mu}_f$, en remplaçant $f$ par une nouvelle fonction $\\tilde{f}$ qui vérifie $\\hat{\\mu}_f = \\hat{\\mu}_{\\tilde{f}}$ sous la mesure $\\pi$, mais avec une variance plus petite $\\mathrm{Var}(\\hat{\\mu}_f) < \\mathrm{Var}(\\hat{\\mu}_{\\tilde{f}})$. \n",
    "\n",
    "Pour y arriver, on utilise une fonction de contrôle $\\psi$ et un opérateur $H$ bien choisis, qui vont nous permettre d'écrire: $$ \\tilde{f}(x)=f(x)+\\frac{H\\psi(x)}{\\sqrt{\\pi(x)}} $$\n",
    "L'idée est donc de choisir le bon $H$ et de choisir la bonne fonction $\\psi$ selon les cas d'usages. Notre projet vise à adapter cette méthode pour un modèle GARCH.\n",
    "\n",
    "Le deuxième article démontre comment la méthode présentée dans le premier peut être mise en œuvre par l'estimateur des moindres carrés ordinaires. En utilisant les variables de contrôle comme covariables et $f(x)$ comme variable expliquée, nous pouvons trouver les coefficients optimaux des variables de contrôle et, par conséquent, les utiliser dans $\\tilde{f}(x)$. Pour le cas du polynôme de premier ordre *(qui sera discuté dans III (Question 2))*, $\\tilde{f}(x)$ peut être écrit : $f(x) + a^T z$ où $z$ est le vecteur des covariables, et $a$ sont les coefficients calculés par une régression OLS de $f(x)$ sur $-z$.\n",
    "\n",
    "Cet article présente également certaines méthodes Lasso (LSLasso et LSLasso(X) en particulier) afin de traiter le cas de polynôme de plus haut degré. En effet, cela permet de réduire le temps de calcul en ne conservant que les variables de contrôle les plus utiles puis d'appliquer des régressions OLS uniquement avec ces variables de contrôle conservées. *Nous en dirons plus sur les méthodes Lasso dans IV (Question 3).*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II - Implementation of a Random Walk Metropolis Sampler\n",
    "\n",
    "*Follow the guidelines given in that experiment to implement a random walk Metropolis sampler that targets the posterior distribution of a GARCH model. For the data, you can use simulated data at first, and then look at the same type of real data (log-returns computed from exchange rates) in a second time.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III - Use of Control Variates\n",
    "\n",
    "*Consider the control variates proposed in the paper (Equation (8), and in particular the versions based on a first-order polynomial, i.e., $f(x) + a^T z$). Explain how you can use these control variates in this setting by doing a linear regression.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV - Expansion to Higher Order Polynomials\n",
    "\n",
    "*Consider a larger set of control variates (by using a polynomial of order 2 for instance). When the number of control variates become too large, the linear regression approach of Step 2 may become too expensive (explain why). Adapt the method proposed in this paper: [https://doi.org/10.1007/s11222-021-10011-z](https://doi.org/10.1007/s11222-021-10011-z), which relies on the Lasso, to your problem, and compare with the naive approach (where you use only a single step based on a linear regression).*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V - Bonus: Linear Regression Validity\n",
    "\n",
    "*Is the fact that we do linear regression completely valid when applied to an MCMC sample? Try to think of ways to address this issue. Hint: you could think of ways to make MCMC simulations less \"dependent\", by sub-sampling, or averaging over blocks of a given size, or another approach.*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
